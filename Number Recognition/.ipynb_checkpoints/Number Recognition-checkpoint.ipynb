{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://towardsdatascience.com/deploying-a-simple-machine-learning-model-into-a-webapp-using-tensorflow-js-3609c297fb04"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are going to use the MNIST dataset, which is a dataset of handwritten digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this dataset, you have 60,000 images, all of them are of size 28 x 28 pixels in grayscale, with pixel values from 0 to 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "from tensorflow.keras.datasets import mnist\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 28s 2us/step\n",
      "X_train.shape: (60000, 28, 28)\n",
      "y_train.shape: (60000,)\n",
      "X_test.shape: (10000, 28, 28)\n",
      "y_test.shape: (10000,)\n"
     ]
    }
   ],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "print (\"X_train.shape: {}\".format(X_train.shape))\n",
    "print (\"y_train.shape: {}\".format(y_train.shape))\n",
    "print (\"X_test.shape: {}\".format(X_test.shape))\n",
    "print (\"y_test.shape: {}\".format(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.subplot(161)\n",
    "plt.imshow(X_train[3], cmap=plt.get_cmap('gray'))\n",
    "plt.subplot(162)\n",
    "plt.imshow(X_train[5], cmap=plt.get_cmap('gray'))\n",
    "plt.subplot(163)\n",
    "plt.imshow(X_train[7], cmap=plt.get_cmap('gray'))\n",
    "plt.subplot(164)\n",
    "plt.imshow(X_train[2], cmap=plt.get_cmap('gray'))\n",
    "plt.subplot(165)\n",
    "plt.imshow(X_train[0], cmap=plt.get_cmap('gray'))\n",
    "plt.subplot(166)\n",
    "plt.imshow(X_train[13], cmap=plt.get_cmap('gray'));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Environment - Google Colab?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-Processing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize inputs: The data comes with values from 0 to 255, we should normalize them to a scale from 0 to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize Inputs from 0–255 to 0–1\n",
    "X_train = X_train / 255\n",
    "X_test = X_test / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encode outputs\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "num_classes = y_test.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flatten 28*28 images to a 784 vector for each image\n",
    "num_pixels = X_train.shape[1] * X_train.shape[2]\n",
    "# X_train = X_train.reshape(X_train.shape[0], num_pixels).astype('float32')\n",
    "# X_test = X_test.reshape(X_test.shape[0], num_pixels).astype('float32')\n",
    "X_train = X_train.reshape((X_train.shape[0], 28, 28, 1)).astype('float32')\n",
    "X_test = X_test.reshape((X_test.shape[0], 28, 28, 1)).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://keras.io/getting-started/sequential-model-guide/\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.add(Dense(num_pixels, input_dim=num_pixels, activation='relu'))\n",
    "# model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.add(Conv2D(30, (5, 5), input_shape=(28, 28, 1), activation='relu'))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Conv2D(15, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/30\n",
      "60000/60000 - 21s - loss: 1.4366 - accuracy: 0.5026 - val_loss: 111.5908 - val_accuracy: 0.6285\n",
      "Epoch 2/30\n",
      "60000/60000 - 22s - loss: 0.5047 - accuracy: 0.8416 - val_loss: 63.3600 - val_accuracy: 0.7992\n",
      "Epoch 3/30\n",
      "60000/60000 - 21s - loss: 0.3411 - accuracy: 0.8936 - val_loss: 35.6209 - val_accuracy: 0.8877\n",
      "Epoch 4/30\n",
      "60000/60000 - 21s - loss: 0.2527 - accuracy: 0.9217 - val_loss: 28.8390 - val_accuracy: 0.9063\n",
      "Epoch 5/30\n",
      "60000/60000 - 22s - loss: 0.2058 - accuracy: 0.9369 - val_loss: 20.5749 - val_accuracy: 0.9313\n",
      "Epoch 6/30\n",
      "60000/60000 - 24s - loss: 0.1750 - accuracy: 0.9451 - val_loss: 16.8913 - val_accuracy: 0.9444\n",
      "Epoch 7/30\n",
      "60000/60000 - 22s - loss: 0.1512 - accuracy: 0.9532 - val_loss: 17.9260 - val_accuracy: 0.9404\n",
      "Epoch 8/30\n",
      "60000/60000 - 22s - loss: 0.1355 - accuracy: 0.9575 - val_loss: 15.4813 - val_accuracy: 0.9520\n",
      "Epoch 9/30\n",
      "60000/60000 - 23s - loss: 0.1223 - accuracy: 0.9612 - val_loss: 17.3844 - val_accuracy: 0.9453\n",
      "Epoch 10/30\n",
      "60000/60000 - 23s - loss: 0.1145 - accuracy: 0.9644 - val_loss: 15.6036 - val_accuracy: 0.9523\n",
      "Epoch 11/30\n",
      "60000/60000 - 19s - loss: 0.1056 - accuracy: 0.9664 - val_loss: 15.5059 - val_accuracy: 0.9519\n",
      "Epoch 12/30\n",
      "60000/60000 - 20s - loss: 0.0977 - accuracy: 0.9692 - val_loss: 11.1154 - val_accuracy: 0.9655\n",
      "Epoch 13/30\n",
      "60000/60000 - 20s - loss: 0.0931 - accuracy: 0.9709 - val_loss: 11.8017 - val_accuracy: 0.9629\n",
      "Epoch 14/30\n",
      "60000/60000 - 20s - loss: 0.0882 - accuracy: 0.9728 - val_loss: 9.7062 - val_accuracy: 0.9687\n",
      "Epoch 15/30\n",
      "60000/60000 - 19s - loss: 0.0812 - accuracy: 0.9744 - val_loss: 11.6600 - val_accuracy: 0.9668\n",
      "Epoch 16/30\n",
      "60000/60000 - 19s - loss: 0.0768 - accuracy: 0.9756 - val_loss: 11.8251 - val_accuracy: 0.9657\n",
      "Epoch 17/30\n",
      "60000/60000 - 19s - loss: 0.0761 - accuracy: 0.9758 - val_loss: 11.6285 - val_accuracy: 0.9669\n",
      "Epoch 18/30\n",
      "60000/60000 - 19s - loss: 0.0714 - accuracy: 0.9778 - val_loss: 10.7512 - val_accuracy: 0.9680\n",
      "Epoch 19/30\n",
      "60000/60000 - 19s - loss: 0.0682 - accuracy: 0.9779 - val_loss: 10.4513 - val_accuracy: 0.9714\n",
      "Epoch 20/30\n",
      "60000/60000 - 19s - loss: 0.0666 - accuracy: 0.9786 - val_loss: 9.4413 - val_accuracy: 0.9736\n",
      "Epoch 21/30\n",
      "60000/60000 - 19s - loss: 0.0634 - accuracy: 0.9798 - val_loss: 10.2800 - val_accuracy: 0.9716\n",
      "Epoch 22/30\n",
      "60000/60000 - 19s - loss: 0.0628 - accuracy: 0.9796 - val_loss: 9.5641 - val_accuracy: 0.9722\n",
      "Epoch 23/30\n",
      "60000/60000 - 19s - loss: 0.0595 - accuracy: 0.9815 - val_loss: 8.9415 - val_accuracy: 0.9752\n",
      "Epoch 24/30\n",
      "60000/60000 - 19s - loss: 0.0578 - accuracy: 0.9820 - val_loss: 10.0452 - val_accuracy: 0.9714\n",
      "Epoch 25/30\n",
      "60000/60000 - 20s - loss: 0.0561 - accuracy: 0.9821 - val_loss: 8.8657 - val_accuracy: 0.9746\n",
      "Epoch 26/30\n",
      "60000/60000 - 26s - loss: 0.0554 - accuracy: 0.9820 - val_loss: 9.5478 - val_accuracy: 0.9738\n",
      "Epoch 27/30\n",
      "60000/60000 - 22s - loss: 0.0534 - accuracy: 0.9829 - val_loss: 7.3034 - val_accuracy: 0.9802\n",
      "Epoch 28/30\n",
      "60000/60000 - 25s - loss: 0.0523 - accuracy: 0.9834 - val_loss: 7.4563 - val_accuracy: 0.9802\n",
      "Epoch 29/30\n",
      "60000/60000 - 24s - loss: 0.0513 - accuracy: 0.9834 - val_loss: 7.9656 - val_accuracy: 0.9770\n",
      "Epoch 30/30\n",
      "60000/60000 - 21s - loss: 0.0503 - accuracy: 0.9836 - val_loss: 8.3022 - val_accuracy: 0.9784\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x632d1abd0>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=30, batch_size=200, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional Deep Model to Improve Accuracy\n",
    "'''\n",
    "x_train_deep_model = x_train.reshape((60000, 28, 28, 1)).astype(‘float32’)\n",
    "x_test_deep_model = x_test.reshape((10000, 28, 28, 1)).astype(‘float32’)\n",
    "deep_model = Sequential()\n",
    "deep_model.add(Conv2D(30, (5, 5), input_shape=(28, 28, 1), activation=’relu’))\n",
    "deep_model.add(MaxPooling2D())\n",
    "deep_model.add(Conv2D(15, (3, 3), activation=’relu’))\n",
    "deep_model.add(MaxPooling2D())\n",
    "deep_model.add(Dropout(0.2))\n",
    "deep_model.add(Flatten())\n",
    "deep_model.add(Dense(128, activation=’relu’))\n",
    "deep_model.add(Dense(50, activation=’relu’))\n",
    "deep_model.add(Dense(num_classes, activation=’softmax’))\n",
    "deep_model.compile(loss=’categorical_crossentropy’, optimizer=’adam’, metrics=[‘accuracy’])\n",
    "deep_model.fit(x_train_deep_model, y_train, validation_data=(x_test_deep_model, y_test), epochs=30, batch_size=200, verbose=2)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting Keras Model to Tensorflow.js"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model into an HDF5 model for download\n",
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/sh: tensorflowjs_converter: command not found\r\n"
     ]
    }
   ],
   "source": [
    "# !pip install tensorflowjs\n",
    "!tensorflowjs_converter --input_format keras '/content/model.h5' '/content/model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'TensorFlow.js needs to be pointed at the JSON file (model.json) and expects a sibling file called “group1-shard1of1.bin”. You need these two files. Download both files. Both of these files are in a folder titled model.'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''TensorFlow.js needs to be pointed at the JSON file (model.json) and expects a sibling file called “group1-shard1of1.bin”. You need these two files. Download both files. Both of these files are in a folder titled model.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HTML5 Canvas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drawing code from: https://www.html5canvastutorials.com/labs/html5-canvas-paint-application/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hooking It Up"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
